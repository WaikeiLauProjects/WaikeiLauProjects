---
title: "Group H Capstone project"
author: "Waikei"
date: "2023-03-20"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#git add --all
#git commit -m "update code"
#git push
#git push --set-upstream origin TrainTestSplit


library(tsibble)
library(lubridate)
library(dplyr)
library(tidyr)
library(sqldf)
library(reticulate)
library(readr)
library(zoo)
library(data.table)


```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r load, include=FALSE}

#~~~Read Tempurature~~~#
Temp_NSW <- read.csv("../data/temperature_nsw.csv") %>%
  na.omit() %>%
  filter(TEMPERATURE >=-500) %>%
  mutate(DATETIME = ymd_hms(DATETIME)) 
# which(is.na(Temp_NSW$DATETIME))

#~~~Read Demand~~~#
Demand_NSW <- read_csv("../data/totaldemand_nsw.csv.zip", show_col_types = FALSE) %>% #read from github
  na.omit() %>% distinct() %>% #remove duplicates and NA values
  mutate(DATETIME = ymd_hms(DATETIME)) %>%
  left_join(Temp_NSW[c(-2)], by=c('DATETIME')) %>% #Add Temperature (To Demand)#
  rename(Temp='TEMPERATURE') %>%
  fill(Temp) %>% select(-2) %>%
  filter(DATETIME>='2019-06-15') #keep 3 years data


#~~~Add Hourly Solar (To Demand)~~~#
#Solar_5min <- na.omit(read_csv('../data/solar.csv', show_col_types = FALSE) %>%
#  mutate(SETTLEMENTDATE =  ymd_hms(SETTLEMENTDATE)) %>%
#  select(1,4) %>%
#  rename(DATETIME=SETTLEMENTDATE, Solar_MW=SS_SOLAR_CLEAREDMW) %>% 
#  mutate(Solar_MW = as.numeric(Solar_MW)))

#Demand_NSW <- Demand_NSW %>% left_join(Solar_5min, by=c('DATETIME'))

```

```{r}
#~~~Create 30min trend DF from Demand~~~#

Trend_Data <- Demand_NSW %>% 
  group_by(DATETIME=ceiling_date(DATETIME, "30 mins")) %>% summarise(
  AvG30_Demand = mean(TOTALDEMAND, na.rm = TRUE), #~~average demand since last half hour
  AvG30_Temp = mean(Temp, na.rm = TRUE) #~~average Temperature since last half hour
  )%>% as.data.frame()

```


```{r}

Demand_NSW <- Demand_NSW %>% mutate(
  Day_Demand = rollmean(TOTALDEMAND, k=288, fill=NA, align='right'), #~~rolling avg demand 24hours
  Day_Temp = rollmean(Temp, k=288, fill=NA, align='right'), #~~rolling avg Temperature 24hours
  Week_Demand = rollmean(TOTALDEMAND, k=2016, fill=NA, align='right'), #~~rolling avg demand 7 days
  Week_Temp = rollmean(Temp, k=2016, fill=NA, align='right') #~~rolling avg Temp 7 days
  )

```


```{r}

Demand_NSW <- Demand_NSW[minute(Demand_NSW$DATETIME)%%30==0,]

Trend_Data <- Trend_Data %>% left_join(Demand_NSW, by=c('DATETIME'))

print(Trend_Data[4225:4235,1:2])
print(subset(Demand_NSW[,1:3], duplicated(DATETIME)|duplicated(DATETIME, fromLast=TRUE)))


```


```{r}

Trend_Data$Half_Lag_Demand <- c(NA, head(Trend_Data$AvG30_Demand, -1))
Trend_Data$Half_Lag_Temp <- c(NA, head(Trend_Data$AvG30_Temp, -1))
Trend_Data$Day_Lag_Demand <- c(rep(NA, 48), head(Trend_Data$Day_Demand, -48))
Trend_Data$Day_Lag_Temp <- c(rep(NA, 48), head(Trend_Data$Day_Temp, -48))
Trend_Data$Week_Lag_Demand <- c(rep(NA, 336), head(Trend_Data$Week_Demand, -336))
Trend_Data$Week_Lag_Temp <- c(rep(NA, 336), head(Trend_Data$Week_Temp, -336))

Trend_Data$Half_Diff_Demand <- Trend_Data$AvG30_Demand - Trend_Data$Half_Lag_Demand
Trend_Data$Half_Diff_Temp <- Trend_Data$AvG30_Temp - Trend_Data$Half_Lag_Temp
Trend_Data$Day_Diff_Demand <- Trend_Data$Day_Demand - Trend_Data$Day_Lag_Demand
Trend_Data$Day_Diff_Temp <- Trend_Data$Day_Temp - Trend_Data$Day_Lag_Temp
Trend_Data$Week_Diff_Demand <- Trend_Data$Week_Demand - Trend_Data$Week_Lag_Demand
Trend_Data$Week_Diff_Temp <- Trend_Data$Week_Temp - Trend_Data$Week_Lag_Temp

```

```{r}

#~~~Add Season (To 30min Forecast)~~~#
#Forecast_Data$season <- ifelse(months(Forecast_Data$DATETIME) %in% month.name[c(12,1,2)], 4,
#                               ifelse(months(Forecast_Data$DATETIME) %in% month.name[c(3,4,5)], 3,
#                                      ifelse(months(Forecast_Data$DATETIME) %in% month.name[c(6,7,8)], 2,1)))


#~~~Add Day of week (To 30min Forecast)~~~#
Trend_Data$Weekday<- lubridate::wday(Trend_Data$DATETIME, label = FALSE)
Trend_Data$Month <- format(as.Date(Trend_Data$DATETIME, format="%d/%m/%Y"),"%m")
Trend_Data$Time <- as.integer(format(as.POSIXct(Trend_Data$DATETIME), format = "%H%M"))


#~~~Add Holidays (To 30min Forecast)~~~#
PublicHolidays <- as.data.frame(tsibble::holiday_aus(year = 2010:2023, state = "NSW"))
PublicHolidays$day <- ifelse(wday(PublicHolidays$date) == 1, 1, ifelse(wday(PublicHolidays$date) == 7, 2,0))
PublicHolidays$Obs <- PublicHolidays$date + PublicHolidays$day
Trend_Data$PubHol <- ifelse(as.Date(Trend_Data$DATETIME,format = "%y-%m-%d") %in% PublicHolidays$Obs, 1, 0)


```

```{r}

#~~~Create T+N target outputs for reinforcement learning~~~#
name= paste("T+",1:336, sep="")
change= paste("Diff+",1:336, sep="")

Trend_Data <- na.omit(Trend_Data)

for(i in 1:336){
  Trend_Data[[name[i]]] <- c(tail(Trend_Data$AvG30_Demand, -i), rep(NA, i))
}

for(i in 1:336){
  Trend_Data[[change[i]]] <- Trend_Data[[name[i]]] - Trend_Data$AvG30_Demand
}

Forecast_Data <- Trend_Data[c(1,16:25,362:697)]

split <-ymd_hms("2021-08-01 00:00:00")
test_end <-ymd_hms("2021-08-08 00:00:00")

#~~~Setting up axis for later plots~~~#
train_actuals <- Trend_Data[Trend_Data$DATETIME<split,]%>%select(2)
test_actuals <- Trend_Data[Trend_Data$DATETIME==split,]%>%select(26:361)
test_axis <- seq(ymd_hms("2021-08-01 00:30:00"), ymd_hms("2021-08-08 00:00:00"), by = "30 min")

print(Forecast_Data)

#~~~Split into train test set~~~#
train <- Forecast_Data[Forecast_Data$DATETIME<split,]
test <- Forecast_Data[Forecast_Data$DATETIME>=split&Forecast_Data$DATETIME<test_end,]


```

```{r}

#~~~Run this to install python packages for the first time~~~#
#repl_python()
#py_install('pandas')
#py_install('numpy')
#py_install('matplotlib')
#py_install('seaborn')

```



```{python}

#~~~MUST RESTART R SESSION TO REFRESH PYTHON ENVIRONMENT~~~#
#py_Forecast_30m.iloc[0:0]

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import RegressorChain
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import make_scorer
from sklearn.model_selection import GridSearchCV
import shap
import time
import pickle

```

```{python}
#~~~create Train Test split for time series~~~#


train_x, train_y, test_x, test_y = r.train.set_index('DATETIME').iloc[:,:10], r.train.set_index('DATETIME').iloc[:,10:], r.test.set_index('DATETIME').iloc[:,:10], r.test.set_index('DATETIME').iloc[:,10:]

#test.iloc[-337:-336,:10] , test.iloc[-337:-336,10:]

```



```{python}
#~~ the TimeSeriesSplit component of below code was adapted from https://towardsdatascience.com/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1

#~~ it provides the necessary modifications to standard Gridsearch to be applicable to time series data

'''
p_search = { 
    'n_estimators': [100, 500, 1000],
    'max_depth' : [5, 10]
}

test_model = RandomForestRegressor(min_samples_leaf = 50, oob_score =True)
tscv = TimeSeriesSplit(n_splits=4)

start = time.time()
gsearch = GridSearchCV(estimator=test_model, cv=tscv, param_grid=p_search, scoring='neg_mean_absolute_percentage_error')
gsearch.fit(train_x, train_y)
stop = time.time()

print(f"Grid Search time: {stop - start}s")

best_score = gsearch.best_score_
best_model = gsearch.best_estimator_

print(best_model)
'''

```


```{python}


best_model = RandomForestRegressor(n_estimators=500, max_depth = 10, min_samples_leaf = 50, oob_score =True)

start = time.time()
best_model.fit(train_x, train_y)
stop = time.time()

print(f"best_model  Training time: {stop - start}s")


```


```{python}

#~~~ Save the model and create predictions on the test X~~~#

pickle.dump(best_model, open('../model/rf_model.sav', 'wb'))

loaded_model = pickle.load(open('../model/rf_model.sav', 'rb'))

pred_y = pd.DataFrame(loaded_model.predict(test_x), columns = r.change).set_index(test_y.index)

```

```{python}

imp = loaded_model.feature_importances_
features = train_x.columns
indices = np.argsort(imp)
plt.title('Feature Importances')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()

```

```{r}

#~~~Compare predictions with equivalent trended actuals~~~#

pred_y = py$pred_y
colnames(pred_y) <- name
ref_xy <- Trend_Data[Trend_Data$DATETIME %in% ymd_hms(row.names(pred_y)),]

#~~~Re-trend the predictions~~~#

for(i in 1:336){
  pred_y[,i] <- pred_y[,i] + ref_xy$AvG30_Demand
}

#~~~ extract the 7 day forecast~~~#
pred_y_7day <- pred_y[1,]

ref_xy <- ref_xy %>% select(26:361)

ref_xy_7day <- ref_xy[1,]

APE <- data.frame(matrix(0, nrow = nrow(pred_y_7day)))

#~~~find APE~~~#

for(i in 1:336){
  APE[[name[i]]] <- abs(pred_y_7day[[name[i]]] - ref_xy_7day[[name[i]]])/ref_xy_7day[[name[i]]]
}

APE <- APE[c(-1)]

#~~~find cMAPE~~~#

cMAPE<-data.frame(matrix(0, nrow = ncol(pred_y_7day)))

for(i in 1:length(APE)){
  cMAPE[c(i),]<-sum(colSums(APE[1:i], na.rm = TRUE))/sum(colSums(!is.na(APE[1:i])))
}

rownames(cMAPE)<-name

colnames(cMAPE)<-"CMAPE"

plot.ts(cMAPE, col = "blue", main = "CMAPE vs Forecasting Horizon")

print(cMAPE)

```


```{r}

#write.csv(pred_y, "../data/RFprediction.csv", row.names=TRUE)

```

```{python}

#~~~Using Out of bag prediction errors to generate prediction interval~~~#

resid = (train_y - loaded_model.oob_prediction_)

lowq = resid.quantile(0.05, axis = 0)
highq = resid.quantile(0.95, axis = 0)

```


```{r}

lq <- t(as.data.frame(py$lowq))
hq <- t(as.data.frame(py$highq))

colnames(lq) <- name
colnames(hq) <- name

lq <- rbind(lq, pred_y)
hq <- rbind(hq, pred_y)

for(i in 2:nrow(lq)){
  lq[i,] <- lq[i,] + lq[1,]
  hq[i,] <- hq[i,] + hq[1,]
}

lq <- lq[-1,]
hq <- hq[-1,]


```

```{python}

#~~~plot the 7 day Forecast and prediction interval

plt.figure(figsize = (18,7))

plt.grid(alpha=0.5)

plt.plot(train_x.index[-337:], r.train_actuals.iloc[-337:], label = "Training observations (truncated)")

plt.plot(r.test_axis, r.test_actuals.iloc[0], color = "blue", label = "Test observations", ls="dashed")

plt.plot(r.test_axis,r.pred_y_7day.iloc[0],color="purple", label = "RF Demand forecast")

plt.fill_between(r.test_axis, r.lq.iloc[0], r.hq.iloc[0], color="purple", alpha=0.5, label = "RF 90% forecast inverval")

plt.legend(fontsize=5)
plt.margins(x=0)
plt.show()

```


```{r}

#~~~check the coverage of the 90% interval~~~#

cover <- na.omit(as.data.frame((ref_xy>=lq) & (ref_xy<=hq)))

col_cover <- as.data.frame(colMeans(cover))
print(col_cover)

```



```{r}

#~~~Table showing the model switching concept~~~#


Model_Switch <- read.csv("../data/consolidated_pbi.csv") %>% mutate(DATETIME = dmy_hm(Datetime)) %>% select(3,11:14) %>% relocate(DATETIME, .before=Demand) %>% pivot_wider(names_from=Model, values_from=c(Forecast,Residual)) %>% select(-10,-18) 

Model_Switch <- Model_Switch %>% mutate(Best_30mModel=
                                          ifelse(apply(abs(Model_Switch[c(10:16)]),1,which.min)==1,"GAM",
                                                 ifelse(apply(abs(Model_Switch[c(10:16)]),1,which.min)==2,"RF",
                                                        ifelse(apply(abs(Model_Switch[c(10:16)]),1,which.min)==3,"XGB",
                                                               ifelse(apply(abs(Model_Switch[c(10:16)]),1,which.min)==4,"LSTM",
                                                                      ifelse(apply(abs(Model_Switch[c(10:16)]),1,which.min)==5,"Linear",
                                                                             ifelse(apply(abs(Model_Switch[c(10:16)]),1,which.min)==6,"Arima1","Arima2")))))),
                                        
                                        best.30.For = ifelse(Best_30mModel=="GAM",Forecast_gam,
                                                             ifelse(Best_30mModel=="RF",Forecast_rf,
                                                                    ifelse(Best_30mModel=="XGB",Forecast_xgb,
                                                                           ifelse(Best_30mModel=="LSTM",Forecast_lstm,
                                                                                  ifelse(Best_30mModel=="Linear",Forecast_linear,
                                                                                         ifelse(Best_30mModel=="Arima1",Forecast_arima1,Forecast_arima2)))))),
                                        
                                        Day_GAM = rollsumr(Model_Switch$Residual_gam, k=48, fill=NA),
                                        Day_RF = rollsumr(Model_Switch$Residual_rf, k=48, fill=NA),
                                        Day_XGB = rollsumr(Model_Switch$Residual_xgb, k=48, fill=NA),
                                        Day_LSTM = rollsumr(Model_Switch$Residual_lstm, k=48, fill=NA),
                                        Day_Linear = rollsumr(Model_Switch$Residual_linear, k=48, fill=NA),
                                        Day_ARIMA1 = rollsumr(Model_Switch$Residual_arima1, k=48, fill=NA),
                                        Day_ARIMA2 = rollsumr(Model_Switch$Residual_arima2, k=48, fill=NA))

Model_Switch <- Model_Switch %>% mutate(Best_1DModel=
                                          ifelse(apply(abs(Model_Switch[c(19:25)]),1,which.min)==1,"GAM",
                                                 ifelse(apply(abs(Model_Switch[c(19:25)]),1,which.min)==2,"RF",
                                                        ifelse(apply(abs(Model_Switch[c(19:25)]),1,which.min)==3,"XGB",
                                                               ifelse(apply(abs(Model_Switch[c(19:25)]),1,which.min)==4,"LSTM",
                                                                      ifelse(apply(abs(Model_Switch[c(19:25)]),1,which.min)==5,"Linear",
                                                                             ifelse(apply(abs(Model_Switch[c(19:25)]),1,which.min)==6,"Arima1","Arima2")))))),
                                        
                                        Wk_GAM = rollsumr(Model_Switch$Residual_gam, k=336, fill=NA),
                                        Wk_RF = rollsumr(Model_Switch$Residual_rf, k=336, fill=NA),
                                        Wk_XGB = rollsumr(Model_Switch$Residual_xgb, k=336, fill=NA),
                                        Wk_LSTM = rollsumr(Model_Switch$Residual_lstm, k=336, fill=NA),
                                        Wk_Linear = rollsumr(Model_Switch$Residual_linear, k=336, fill=NA),
                                        Wk_ARIMA1 = rollsumr(Model_Switch$Residual_arima1, k=336, fill=NA),
                                        Wk_ARIMA2 = rollsumr(Model_Switch$Residual_arima2, k=336, fill=NA))

Model_Switch <- Model_Switch %>% mutate(Best_7DModel=
                                          ifelse(apply(abs(Model_Switch[c(27:33)]),1,which.min)==1,"GAM",
                                                 ifelse(apply(abs(Model_Switch[c(27:33)]),1,which.min)==2,"RF",
                                                        ifelse(apply(abs(Model_Switch[c(27:33)]),1,which.min)==3,"XGB",
                                                               ifelse(apply(abs(Model_Switch[c(27:33)]),1,which.min)==4,"LSTM",
                                                                      ifelse(apply(abs(Model_Switch[c(27:33)]),1,which.min)==5,"Linear",
                                                                             ifelse(apply(abs(Model_Switch[c(27:33)]),1,which.min)==6,"Arima1","Arima2"))))))
                                        
                                                 ) %>% select(1,17,18,26,34) %>% na.omit()




#  mutate(Best = apply(abs(Model_Switch[c(10:16)]),1,FUN=min,na.rm=TRUE))

# Model_Switch <- read.csv("../data/consolidated_pbi.csv") %>% select(-1) %>% 
#   mutate(DATETIME = 
#            seq(ymd_hms("2021-08-01 00:30:00"), ymd_hms("2021-08-08 00:00:00"), by = "30 min"),
#          Demand = ifelse(DATETIME %in% Demand_NSW$DATETIME, Demand_NSW$TOTALDEMAND, NA),
#          RF_pred = pred_y[ymd_hms(row.names(pred_y)) %in% Model_Switch$DATETIME,1],
#          AR_Sigma = (Point.Forecast - Demand),
#          RF_Sigma = (RF_pred - Demand),
#          Best_30m_model = ifelse(abs(AR_Sigma)>abs(RF_Sigma),"RF","ARIMA"),
#          Best_30m_forecast = ifelse(abs(AR_Sigma)>abs(RF_Sigma),RF_pred,Point.Forecast),
#          ARIMA = ifelse(Best_30m_model == "ARIMA", 1,0),
#          RF = ifelse(Best_30m_model == "RF", 1,0),
#          RS_AR_day = rollsumr(ARIMA,k=48,fill=NA),
#          RS_RF_day = rollsumr(RF,k=48,fill=NA),
#          Best_24h_model = ifelse((RS_AR_day)>(RS_RF_day),"ARIMA","RF"),
#          RS_AR_Wk = rollsumr(ARIMA,k=336,fill=NA),
#          RS_RF_Wk = rollsumr(RF,k=336,fill=NA),
#          Best_Wk_model = ifelse((RS_AR_Wk)>(RS_RF_Wk),"ARIMA","RF")) %>%
#   relocate(DATETIME, .before=Point.Forecast) %>%
#   relocate(Demand, .before=Point.Forecast) %>%
#   rename(AR_pred=Point.Forecast) %>% select(-4,-5,-6,-7,-9,-10,-13,-14,-15,-16,-18,-19)
# 


#%>% select(1,2,7,8)

#%>% mutate(T = c(tail(ARIMA_forecast$T+1, -1), NA))

#for(i in 1:48){
#  ARIMA_forecast[[name[i]]] <- c(tail(ARIMA_forecast$T, -i), rep(NA, i))
#}

```

```{r}

write.csv(ARIMA_forecast, "../data/Totalprediction.csv", row.names=TRUE)

```



